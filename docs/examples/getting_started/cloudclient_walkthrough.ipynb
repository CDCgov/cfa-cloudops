{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c84268",
   "metadata": {},
   "source": [
    "# CloudClient Walkthrough\n",
    "\n",
    "This notebook is intended to walk a new user through a full workflow using `cfa-cloudops`. It will take you from initializing the client and uploading files to Blob Storage to creating a pool and running a job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5104b0",
   "metadata": {},
   "source": [
    "## Import and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a51f5e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# import the cloudclient class\n",
    "from cfa.cloudops import CloudClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f671d",
   "metadata": {},
   "source": [
    "The initialization below is the simplest way to create and instance of the `CloudClient` class. It will use environment variables or values stored in a .env file to authenticate, like the .env file stored [here](../../files/sample.env), and a managed identity credential based on your local working environment. The .env file should be stored at the same level in the directory in which you're working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace39726",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "cc = CloudClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e55aa",
   "metadata": {},
   "source": [
    "There are other methods of intializing the CloudClient, such as pointing to a different location of the .env file (perhaps it's called my_azure.env), or using a service principal or federated token for the credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217ae14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## use a different path to .env file - uncomment if desired to run\n",
    "# cc = CloudClient(dotenv_path = 'my_azure.env')\n",
    "\n",
    "## use a service principal instead\n",
    "# cc = CloudClient(use_sp = True)\n",
    "\n",
    "\n",
    "## use a federated token\n",
    "# cc = CloudClient(use_federated = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e739e7",
   "metadata": {},
   "source": [
    "## Upload to Blob Storage\n",
    "\n",
    "There are plenty of times when local files would need to be uploaded to Blob Storage. Files can be referenced from within a running job via a mount in the pool. Scripts in Blob Storage can also be referenced in the command line for the task execution.\n",
    "\n",
    "For example, we have the `main.py` file that we want to upload to the Blob container 'input-test' in order to use it for a future task. The following code will upload to the root of the specified container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84cfd36",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cc.upload_files(\n",
    "    \"main.py\",\n",
    "    container_name = \"input-test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f65c7b6",
   "metadata": {},
   "source": [
    "## Upload Image to Container Registry\n",
    "\n",
    "Batch pools can use images from Azure Container Registry, GitHub Container Registry, or Docker Hub. Suppose we want to package the local Dockerfile (python image with a few requirements) and upload to the Azure Container Registry for use by the pool. The following code would do the trick. Make sure to reference the correct registry name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321e2f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "container_name = cc.package_and_upload_dockerfile(\n",
    "    registry_name = \"my_azure_registry\",\n",
    "    repo_name = \"simple_test\",\n",
    "    tag = \"latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef93284",
   "metadata": {},
   "source": [
    "## Create a Pool\n",
    "\n",
    "Pools are usually created for each team or per project. It spins up nodes when necessary based on the container you specify. The following would create a pool based on the Docker image we just uploaded, autoscaling to 5 nodes, mounting to the 'input-test' container we uploaded to (with relative mount path 'inputs'), an 8 core CPU, and call it 'getting-started-pool'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9aea58",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cc.create_pool(\n",
    "    \"getting-started-pool\",\n",
    "    mounts = [('input-test', 'inputs')],\n",
    "    container_image_name = container_name,\n",
    "    vm_size = \"standard_d8s_v3\",\n",
    "    max_autoscale_nodes = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd84614",
   "metadata": {},
   "source": [
    "## Create a Job\n",
    "\n",
    "Now we can create a job to run our set of tasks. Let's call it 'getting-started-job'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e2d9e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cc.create_job(\n",
    "    \"getting-started-job\",\n",
    "    pool_name = \"getting-started-pool\",\n",
    "    exist_ok = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed48071",
   "metadata": {},
   "source": [
    "## Add Tasks to Job\n",
    "\n",
    "At this point we are ready to add tasks to the job we created. We can run the `main.py` python script that we uploaded to the 'input-test' container. It takes an argument called '--user' and prints a welcome message to the console. We will add two tasks to our job for two different users. In general, any number of tasks can be added to a job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4ef3d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cc.add_task(\n",
    "    job_name = \"getting-started-job\",\n",
    "    command_line = \"python3 /inputs/main.py --user Ryan\"\n",
    ")\n",
    "\n",
    "cc.add_task(\n",
    "    job_name = \"getting-started-job\",\n",
    "    command_line = \"python3 /inputs/main.py --user Phil\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92511278",
   "metadata": {},
   "source": [
    "## Monitor the Job\n",
    "\n",
    "Now that a job is created and tasks are added to it, we can monitor it locally in our terminal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3a742",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cc.monitor_job(\n",
    "    \"getting-started-job\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c2810c",
   "metadata": {},
   "source": [
    "## Delete Services\n",
    "\n",
    "Suppose we want to delete the job and the pool now that the job has completed. The following would remove both from Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990a8ef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# delete the job\n",
    "cc.delete_job(\"getting-started-job\")\n",
    "\n",
    "# delete the pool\n",
    "cc.delete_pool(\"getting-started-pool\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
